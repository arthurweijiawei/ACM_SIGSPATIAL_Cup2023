{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wMZ8F_jEtyIR"
   },
   "source": [
    "   Author: Ankit Kariryaa, University of Bremen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "Define the paths to the dataset and trained models in the `notebooks/config/UNetTraining.py` file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)]\n",
      "D:\\Software\\anaconda\\envs\\acmtensorflow\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(sys.executable)\n",
    "#sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adadelta.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "import time\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from functools import reduce\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "#from core.UNet import UNet\n",
    "from core.UNetAttention import UNet  # upgrade UNet\n",
    "from core.losses import tversky, accuracy, dice_coef, dice_loss, specificity, sensitivity\n",
    "from core.losses_FTL import focalTversky,accuracy,dice_coef,dice_loss,true_positives,false_positives,true_negatives,false_negatives,sensitivity,specificity,PA,IoU_Pos,IoU_Neg,mIoU,F1_Score\n",
    "from core.optimizers import adaDelta\n",
    "# from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.split_frames import split_dataset\n",
    "from core.visualize import display_images\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# ——————\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "# from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1197791086570611488\n",
      "xla_global_id: -1\n",
      "]\n",
      "2.11.0\n",
      "WARNING:tensorflow:From C:\\Users\\Gavin\\AppData\\Local\\Temp\\ipykernel_13920\\895015121.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Gavin\\AppData\\Local\\Temp\\ipykernel_13920\\895015121.py:10: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# GPU\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "\n",
    "config1 = tf.compat.v1.ConfigProto(allow_soft_placement=False, log_device_placement=False)\n",
    "config1.gpu_options.allow_growth = True\n",
    "session=tf.compat.v1.Session(config=config1)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required configurations (including the input and output paths) are stored in a separate file (such as config/UNetTraining.py)\n",
    "# Please provide required info in the file before continuing with this notebook. \n",
    " \n",
    "from config import UNetTraining\n",
    "# In case you are using a different folder name such as configLargeCluster, then you should import from the respective folder\n",
    "# Eg. from configLargeCluster import UNetTraining\n",
    "config = UNetTraining.Configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "all_files = os.listdir(config.base_dir)\n",
    "#all_files=all_files[:len(all_files)//2]\n",
    "all_files_pan = [fn for fn in all_files if fn.startswith(config.pan_fn) and fn.endswith(config.image_type)]\n",
    "for i, fn in enumerate(all_files_pan):\n",
    "    pan_img = rasterio.open(os.path.join(config.base_dir, fn))\n",
    "    #pan_img = rasterio.open(os.path.join(config.base_dir, fn.replace(config.ndvi_fn,config.pan_fn)))\n",
    "    #read_ndvi_img = ndvi_img.read()\n",
    "    read_pan_img = pan_img.read()\n",
    "    # print(read_pan_img.shape)\n",
    "    # (3, 524, 524)\n",
    "    #comb_img = np.concatenate((read_ndvi_img, read_pan_img), axis=0)\n",
    "    #comb_img = np.transpose(pan_img, axes=(1,2,0)) #Channel at the end\n",
    "    #print(fn)\n",
    "    annotation_im = Image.open(os.path.join(config.base_dir, fn.replace(config.pan_fn,config.annotation_fn)[:-4]+\".tif\"))\n",
    "    annotation = np.array(annotation_im)\n",
    "    # print(annotation.shape)\n",
    "    # (524, 524)\n",
    "    weight_im = Image.open(os.path.join(config.base_dir, fn.replace(config.pan_fn,config.weight_fn)[:-4]+\".tif\"))\n",
    "    weight = np.array(weight_im)\n",
    "    # print(weight.shape)\n",
    "    # (524, 524)\n",
    "    f = FrameInfo(read_pan_img, annotation, weight)\n",
    "    #print(f)\n",
    "    frames.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train-test split from file\n",
      "training_frames [87, 90, 26, 210, 119, 174, 71, 186, 15, 183, 108, 216, 60, 105, 193, 195, 70, 148, 227, 79, 11, 157, 74, 167, 10, 45, 165, 151, 194, 65, 92, 123, 59, 31, 4, 93, 139, 152, 173, 180, 124, 149, 19, 197, 163, 6, 147, 72, 38, 21, 1, 208, 214, 191, 175, 211, 205, 35, 68, 219, 203, 23, 144, 98, 196, 22, 16, 20, 179, 223, 82, 29, 184, 131, 101, 78, 30, 141, 155, 110, 140, 117, 40, 127, 202, 192, 32, 168, 135, 91, 222, 185, 106, 226, 125, 153, 27, 190, 28, 221, 170, 199, 177, 128, 171, 97, 218, 156, 134, 159, 8, 86, 62, 88, 39, 201, 207, 42, 102, 118, 5, 13, 215, 66, 37, 178, 17, 111, 96, 85, 67, 48, 189, 161, 14, 104, 63, 200, 116, 9, 84, 107, 49, 130, 212]\n",
      "validation_frames [94, 73, 56, 41, 143, 213, 133, 3, 103, 188, 176, 126, 187, 75, 158, 142, 12, 47, 61, 2, 154, 209, 100, 52, 122, 150, 25, 58, 80, 198, 121, 24, 43, 181, 115, 217, 51]\n",
      "testing_frames [18, 138, 109, 99, 76, 36, 132, 220, 136, 0, 64, 112, 225, 77, 44, 182, 57, 160, 53, 69, 83, 81, 34, 172, 162, 113, 50, 120, 33, 206, 54, 166, 145, 95, 164, 137, 146, 114, 169, 224, 46, 129, 55, 7, 204, 89]\n",
      "145\n",
      "37\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "training_frames, validation_frames, testing_frames  = split_dataset(frames, config.frames_json, config.patch_dir)\n",
    "# training_frames = validation_frames = testing_frames  = list(range(len(frames)))\n",
    "# print(len(training_frames))\n",
    "# print(len(validation_frames))\n",
    "# print(len(testing_frames))\n",
    "annotation_channels = config.input_label_channel + config.input_weight_channel\n",
    "train_generator = DataGenerator(config.input_image_channel, config.patch_size, training_frames, frames, annotation_channels, augmenter = 'iaa').random_generator(config.BATCH_SIZE, normalize = config.normalize)\n",
    "val_generator = DataGenerator(config.input_image_channel, config.patch_size, validation_frames, frames, annotation_channels, augmenter= None).random_generator(config.BATCH_SIZE, normalize = config.normalize)\n",
    "test_generator = DataGenerator(config.input_image_channel, config.patch_size, testing_frames, frames, annotation_channels, augmenter= None).random_generator(config.BATCH_SIZE, normalize = config.normalize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIMIZER = adaDelta\n",
    "# LOSS = tversky\n",
    "LOSS = focalTversky\n",
    "#Only for the name of the model in the very end\n",
    "OPTIMIZER_NAME = 'AdaDelta'\n",
    "# LOSS_NAME = 'weightmap_tversky'\n",
    "LOSS_NAME = 'weightmap_focalTversky'\n",
    "\n",
    "\n",
    "# Declare the path to the final model\n",
    "# If you want to retrain an exising model then change the cell where model is declared.\n",
    "# This path is for storing a model after training.\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = config.input_image_channel + config.input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '')\n",
    "\n",
    "print(\"0\")\n",
    "if not os.path.exists(config.model_path):\n",
    "    os.makedirs(config.model_path)\n",
    "model_path = os.path.join(config.model_path,'trees_{}_{}_{}_{}_{}.h5'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs,config.input_shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Input (InputLayer)             [(None, 512, 512, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 512, 512, 64  2368        ['Input[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 512, 512, 64  36928       ['conv2d_38[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 512, 512, 64  256        ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 256, 256, 64  0          ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 256, 256, 12  73856       ['max_pooling2d_8[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 256, 256, 12  147584      ['conv2d_40[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 256, 256, 12  512        ['conv2d_41[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 128, 128, 12  0          ['batch_normalization_17[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 128, 128, 25  295168      ['max_pooling2d_9[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 128, 128, 25  590080      ['conv2d_42[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 128, 128, 25  1024       ['conv2d_43[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 64, 64, 256)  0          ['batch_normalization_18[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 64, 64, 512)  1180160     ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 64, 64, 512)  2359808     ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 32, 32, 512)  0          ['batch_normalization_19[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 32, 32, 1024  4719616     ['max_pooling2d_11[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 32, 32, 1024  9438208     ['conv2d_46[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_8 (UpSampling2D)  (None, 64, 64, 1024  0          ['conv2d_47[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 64, 64, 1024  4096       ['up_sampling2d_8[0][0]']        \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 64, 64, 1536  0           ['batch_normalization_20[0][0]', \n",
      "                                )                                 'batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 64, 64, 512)  7078400     ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 64, 64, 512)  2359808     ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d_9 (UpSampling2D)  (None, 128, 128, 51  0          ['conv2d_49[0][0]']              \n",
      "                                2)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 128, 128, 51  2048       ['up_sampling2d_9[0][0]']        \n",
      " ormalization)                  2)                                                                \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 128, 128, 76  0           ['batch_normalization_21[0][0]', \n",
      "                                8)                                'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 128, 128, 25  1769728     ['concatenate_9[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_51 (Conv2D)             (None, 128, 128, 25  590080      ['conv2d_50[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_10 (UpSampling2D  (None, 256, 256, 25  0          ['conv2d_51[0][0]']              \n",
      " )                              6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 256, 256, 25  1024       ['up_sampling2d_10[0][0]']       \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 256, 256, 38  0           ['batch_normalization_22[0][0]', \n",
      "                                4)                                'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 256, 256, 12  442496      ['concatenate_10[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 256, 256, 12  147584      ['conv2d_52[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_11 (UpSampling2D  (None, 512, 512, 12  0          ['conv2d_53[0][0]']              \n",
      " )                              8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 512, 512, 12  512        ['up_sampling2d_11[0][0]']       \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 512, 512, 19  0           ['batch_normalization_23[0][0]', \n",
      "                                2)                                'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 512, 512, 64  110656      ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 512, 512, 64  36928       ['conv2d_54[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 512, 512, 1)  65          ['conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,391,041\n",
      "Trainable params: 31,385,281\n",
      "Non-trainable params: 5,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31648\\4034021651.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define the model and compile it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_label_channel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#focalTversky,accuracy,dice_coef,dice_loss,true_positives,false_positives,true_negatives,false_negatives,sensitivity,specificity,PA,IoU_Pos,IoU_Neg,mIoU,F1_Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, specificity, sensitivity, accuracy])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "# Define the model and compile it\n",
    "model = UNet([config.BATCH_SIZE, *config.input_shape],config.input_label_channel)\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[accuracy,dice_coef,dice_loss,true_positives,false_positives,true_negatives,false_negatives,sensitivity,specificity,PA,IoU_Pos,IoU_Neg,mIoU,F1_Score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min', save_weights_only = False)\n",
    "\n",
    "log_dir = os.path.join(config.model_path,'UNet_{}_{}_{}_{}_{}'.format(timestr,OPTIMIZER_NAME,LOSS_NAME,chs, config.input_shape[0]))\n",
    "tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "reduceLROnPlat =ReduceLROnPlateau(monitor='val_loss',factor=0.33,patience=5,verbose=1,mode='min',min_delta=0.001,cooldown=4,min_lr=1e-16)\n",
    "early = EarlyStopping(monitor=\"val_loss\",mode=\"min\",verbose=2,patience=50)\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard,early] #reduceLROnPlat is not required with adaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = [model.fit(train_generator,\n",
    "                         steps_per_epoch=config.MAX_TRAIN_STEPS,\n",
    "                         epochs=config.NB_EPOCHS,\n",
    "                         validation_data=val_generator,\n",
    "                         validation_steps=config.VALID_IMG_COUNT,\n",
    "                         callbacks=callbacks_list,\n",
    "                         workers=1,\n",
    "                          )]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOeYCBzQRMr8FXNUC8za+ng",
   "collapsed_sections": [],
   "name": "step3-Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "acmtensorflow",
   "language": "python",
   "name": "acmtensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
