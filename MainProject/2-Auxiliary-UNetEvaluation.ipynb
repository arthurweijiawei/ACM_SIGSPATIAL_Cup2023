{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np               # numerical array manipulation\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "#import fiona     # I/O raster data (netcdf, height, geotiff, ...)\n",
    "import rasterio.warp             # Reproject raster samples\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.geometry import mapping, shape\n",
    "# import fiona\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from core.UNet import UNet\n",
    "from core.losses_FTL import focalTversky,accuracy,dice_coef,dice_loss,true_positives,false_positives,true_negatives,false_negatives,sensitivity,specificity,PA,IoU_Pos,IoU_Neg,mIoU,F1_Score\n",
    "from core.optimizers import adaDelta\n",
    "#, adagrad, adam, nadam\n",
    "from core.frame_info import FrameInfo\n",
    "from core.dataset_generator import DataGenerator\n",
    "from core.split_frames import split_dataset\n",
    "from core.visualize import display_images\n",
    "\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # plotting tools\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import warnings                  # ignore annoying warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "#reload_ext autoreload\n",
    "#%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = r'D:\\ACM\\ModelResult0930_Final\\PreDataSetFinal'\n",
    "model_dir = r'D:\\ACM\\ModelResult0930_Final'\n",
    "image_type = '.png'\n",
    "annotation_weight_type = '.tif'\n",
    "pan_fn = 'pan'\n",
    "annotation_fn = 'annotation'\n",
    "weight_fn = 'boundary'\n",
    "\n",
    "# For testing, images are divided into sequential patches\n",
    "patch_generation_stratergy = 'sequential'\n",
    "patch_size = (512,512,5)\n",
    "BATCH_SIZE = 8 # Model is evaluated in batches; See https://keras.io/models/model/#evaluate\n",
    "\n",
    "# # When stratergy == sequential\n",
    "step_size = (512,512)\n",
    "\n",
    "\n",
    "# The data has four channels\n",
    "# The order is [ PAN, ANNOTATION, WEIGHT]\n",
    "input_shape = (512,512,3)\n",
    "input_image_channel = [0,1,2]\n",
    "input_label_channel = [3]\n",
    "input_weight_channel = [4]\n",
    "\n",
    "OPTIMIZER = adaDelta\n",
    "LOSS = focalTversky\n",
    "\n",
    "OPTIMIZER_NAME = 'adaDelta'\n",
    "LOSS_NAME = 'weightmap_focalTversky'\n",
    "\n",
    "modelToEvaluate =r'D:\\ACM\\ModelResult0930_Final\\trees_20230930-2149_AdaDelta_weightmap_focalTversky_0123_512.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File path for final report \n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "chf = input_image_channel + input_label_channel\n",
    "chs = reduce(lambda a,b: a+str(b), chf, '')\n",
    "\n",
    "evaluation_report_path = model_path = model_dir\n",
    "if not os.path.exists(evaluation_report_path):\n",
    "    os.makedirs(evaluation_report_path)\n",
    "evaluation_report_filename = os.path.join(evaluation_report_path,'evaluation_per_pixel{}_{}.csv'.format(timestr,chs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all images/frames into memory\n",
    "frames = []\n",
    "\n",
    "all_files = os.listdir(base_dir)\n",
    "all_files_pan = [fn for fn in all_files if fn.startswith(pan_fn) and fn.endswith(image_type)]\n",
    "len(all_files_pan)\n",
    "#dtype = {'F': np.float32, 'L': np.uint8}[pil_img.mode]\n",
    "\n",
    "for i, fn in enumerate(tqdm(all_files_pan)):\n",
    "    pan_img = rasterio.open(os.path.join(base_dir, fn))\n",
    "    read_pan_img = pan_img.read()\n",
    "    annotation_im = Image.open(os.path.join(base_dir, fn.replace(pan_fn,annotation_fn).replace(image_type,annotation_weight_type)))\n",
    "    annotation = np.array(annotation_im)\n",
    "    weight_im = Image.open(os.path.join(base_dir, fn.replace(pan_fn,weight_fn).replace(image_type,annotation_weight_type)))\n",
    "    weight = np.array(weight_im)\n",
    "    f = FrameInfo(read_pan_img, annotation, weight)\n",
    "    frames.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing on all frames. All sequential frames are kept in memory and this may create memory related errors in some cases. \n",
    "testing_frames  = list(range(len(frames)))\n",
    "\n",
    "annotation_channels = input_label_channel + input_weight_channel\n",
    "test_generator = DataGenerator(input_image_channel, patch_size, testing_frames, frames, annotation_channels)\n",
    "\n",
    "# Sequential generate all patches from the all frames\n",
    "test_patches = test_generator.all_sequential_patches(step_size)\n",
    "print('Total patches to evaluate the model on: ' + str(len(test_patches[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the some of the test images\n",
    "# numberOfImagesToDisplay = 10\n",
    "\n",
    "# train_images, real_label = test_patches[0][:numberOfImagesToDisplay], test_patches[1][:numberOfImagesToDisplay]\n",
    "# display_images(np.concatenate((train_images,real_label), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate model\n",
    "def evaluate_model(model_path, evaluation_report_filename):\n",
    "    print(model_path, evaluation_report_filename)\n",
    "    model = load_model(model_path, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy , 'specificity': specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity])\n",
    "    print('Evaluating model now!')\n",
    "    ev = model.evaluate(x=test_patches[0], y=test_patches[1],  verbose=1, use_multiprocessing=True)\n",
    "    report  = dict(zip(model.metrics_names, ev))\n",
    "    report['model_path'] =  model_path\n",
    "    report['test_frame_dir']= base_dir\n",
    "    report['total_patch_count']= len(test_patches[0])\n",
    "    return report\n",
    "\n",
    "report = evaluate_model(modelToEvaluate, evaluation_report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the model predictions!\n",
    "model = load_model(modelToEvaluate, custom_objects={'tversky': tversky, 'dice_coef': dice_coef, 'dice_loss':dice_loss, 'accuracy':accuracy , 'specificity': specificity, 'sensitivity':sensitivity}, compile=False)\n",
    "model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=[dice_coef, dice_loss, accuracy, specificity, sensitivity])\n",
    "predictions = []\n",
    "for tp in test_patches[0]:\n",
    "    tpx = np.expand_dims(tp, axis=0)\n",
    "    modelpredtictions = model.predict(tpx, batch_size=BATCH_SIZE)\n",
    "    predictions.append(np.squeeze(modelpredtictions, axis = 0))\n",
    "\n",
    "display_images(np.concatenate((test_patches[0], test_patches[1][...,[0]], predictions), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Contours from image to world coordinates  \n",
    "def transform_contours_to_xy(contours, transform):\n",
    "    tp = []\n",
    "    for cnt in contours:\n",
    "        pl = cnt[:, 0, :]\n",
    "        cols, rows = zip(*pl)\n",
    "        x,y = rasterio.transform.xy(transform, rows, cols)\n",
    "        tl = [list(i) for i in zip(x, y)]\n",
    "        tp.append(tl)\n",
    "    return (tp)\n",
    "\n",
    "def mask_to_polygons(mask, transform, th = 0.5):\n",
    "    # first, find contours with cv2: it's much faster than shapely and returns hierarchy\n",
    "    mask[mask < th] = 0\n",
    "    mask[mask >= th] = 1\n",
    "    mask = ((mask) * 255).astype(np.uint8)\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #Convert contours from image coordinate to xy coordinate (world coordinates)\n",
    "    contours = transform_contours_to_xy(contours, transform)\n",
    "\n",
    "    if not contours: #TODO: Raise an error maybe\n",
    "        print('Warning: No contours/polygons detected!!')\n",
    "        return [Polygon()]#[Polygon()]\n",
    "    \n",
    "    # now messy stuff to associate parent and child contours\n",
    "    cnt_children = defaultdict(list)\n",
    "    child_contours = set()\n",
    "    assert hierarchy.shape[0] == 1\n",
    "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
    "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
    "        if parent_idx != -1:\n",
    "            child_contours.add(idx)\n",
    "            cnt_children[parent_idx].append(contours[idx])\n",
    "    # create actual polygons filtering by area/hole (removes artifacts)\n",
    "    all_polygons = []\n",
    "    for idx, cnt in enumerate(contours):\n",
    "        if idx not in child_contours: #and cv2.contourArea(cnt) >= min_area: #Do we need to check for min_area??\n",
    "            try:\n",
    "                poly = Polygon(\n",
    "                    shell=cnt,\n",
    "                    holes=[c for c in cnt_children.get(idx, [])])\n",
    "                           #if cv2.contourArea(c) >= min_area]) #Do we need to check for min_area??\n",
    "                all_polygons.append(poly)\n",
    "            except Exception as e: \n",
    "#                 print(e)\n",
    "                pass\n",
    "#     print(len(all_polygons))\n",
    "    return(all_polygons)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acmtensorflow",
   "language": "python",
   "name": "acmtensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
